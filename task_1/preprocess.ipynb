{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat_file(file_path):\n",
    "    \"\"\"Load vibration signal from a .mat file, extracting from the correct field.\"\"\"\n",
    "    mat_data = scipy.io.loadmat(file_path, struct_as_record=False, squeeze_me=True)\n",
    "    if 'bearing' in mat_data:\n",
    "        structured_array = mat_data['bearing']\n",
    "        if hasattr(structured_array, 'gs') and isinstance(structured_array.gs, np.ndarray):\n",
    "            signal = structured_array.gs.squeeze()\n",
    "            if signal.ndim == 1 and signal.size > 0:\n",
    "                return signal\n",
    "    return None\n",
    "\n",
    "def generate_spectrogram(signal, sample_rate=10000, n_fft=256, hop_length=128):\n",
    "    \"\"\"Convert a 1D vibration signal to a 2D spectrogram using STFT.\"\"\"\n",
    "    spectrogram_transform = T.Spectrogram(n_fft=n_fft, hop_length=hop_length, power=2)\n",
    "    signal_tensor = torch.tensor(signal, dtype=torch.float32).unsqueeze(0)\n",
    "    spectrogram = spectrogram_transform(signal_tensor)\n",
    "    return spectrogram.squeeze().numpy()\n",
    "\n",
    "def preprocess_spectrogram(spectrogram):\n",
    "    \"\"\"Normalize and resize spectrogram to 224x224 pixels.\"\"\"\n",
    "    spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min() + 1e-6)\n",
    "    spectrogram = (spectrogram * 255).astype(np.uint8)\n",
    "    image = Image.fromarray(spectrogram)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    \"\"\"Process all .mat files in the dataset directory and convert them to spectrograms.\"\"\"\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    label_map = {'1 - Three Baseline Conditions': 0, \n",
    "                '2 - Three Outer Race Fault Conditions': 1, \n",
    "                '3 - Seven More Outer Race Fault Conditions': 2, \n",
    "                '4 - Seven Inner Race Fault Conditions': 3}  # Mapping fault conditions \n",
    "\n",
    "    \n",
    "    for label, label_id in label_map.items():\n",
    "        folder_path = os.path.join(dataset_path, label)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: Folder {folder_path} not found.\")\n",
    "            continue\n",
    "        \n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith('.mat'):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                signal = load_mat_file(file_path)\n",
    "                if signal is not None:\n",
    "                    spec = generate_spectrogram(signal)\n",
    "                    spec_tensor = preprocess_spectrogram(spec)\n",
    "                    spectrograms.append(spec_tensor)\n",
    "                    labels.append(label_id)\n",
    "                else:\n",
    "                    print(f\"Warning: No valid signal found in {file_path}\")\n",
    "    \n",
    "    if not spectrograms:\n",
    "        raise RuntimeError(\"No valid data found in the dataset. Ensure .mat files contain the correct 'bearing' structure.\")\n",
    "    \n",
    "    return torch.stack(spectrograms), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data\"\n",
    "try:\n",
    "    x_data, y_labels = process_dataset(dataset_path)\n",
    "    print(\"Processed Data Shape:\", x_data.shape, \"Labels Shape:\", y_labels.shape)\n",
    "except RuntimeError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Model: ResNet-50 + EfficientNet-B0\n",
    "class HybridResNetEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(HybridResNetEfficientNet, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet-50 as feature extractor\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet_features = nn.Sequential(*list(resnet.children())[:-2])  # Remove last FC layer\n",
    "        for param in self.resnet_features.parameters():\n",
    "            param.requires_grad = False  # Freeze ResNet weights\n",
    "        \n",
    "        # Transition layer to align feature dimensions\n",
    "        self.transition = nn.Conv2d(in_channels=2048, out_channels=1280, kernel_size=1)\n",
    "        \n",
    "        # Load pre-trained EfficientNet-B0 as classifier\n",
    "        efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        self.efficientnet_features = efficientnet.features  # Extract feature layers\n",
    "        \n",
    "        # Custom classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet_features(x)  # Feature extraction via ResNet-50\n",
    "        x = self.transition(x)  # Dimension alignment\n",
    "        x = self.efficientnet_features(x)  # Feature extraction via EfficientNet-B0\n",
    "        x = self.classifier(x)  # Classification head\n",
    "        return x\n",
    "\n",
    "# Custom Dataset Class\n",
    "class VibrationDataset(Dataset):\n",
    "    def __init__(self, data_tensors, labels):\n",
    "        self.data_tensors = data_tensors\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data_tensors[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Load and Split Dataset\n",
    "def prepare_dataloaders(data, labels, batch_size=16):\n",
    "    dataset = VibrationDataset(data, labels)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_count = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            if early_stop_count >= 5:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(data_loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Model: ResNet-50 + EfficientNet-B0\n",
    "class HybridResNetEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(HybridResNetEfficientNet, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet-50 as feature extractor\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet_features = nn.Sequential(*list(resnet.children())[:-2])  # Remove last FC layer\n",
    "        for param in self.resnet_features.parameters():\n",
    "            param.requires_grad = False  # Freeze ResNet weights\n",
    "        \n",
    "        # Transition layer to align feature dimensions\n",
    "        self.transition = nn.Conv2d(in_channels=2048, out_channels=1280, kernel_size=1)\n",
    "        \n",
    "        # Load pre-trained EfficientNet-B0 as classifier\n",
    "        efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        self.efficientnet_features = efficientnet.features  # Extract feature layers\n",
    "        \n",
    "        # Custom classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet_features(x)  # Feature extraction via ResNet-50\n",
    "        x = self.transition(x)  # Dimension alignment\n",
    "        x = self.efficientnet_features(x)  # Feature extraction via EfficientNet-B0\n",
    "        x = self.classifier(x)  # Classification head\n",
    "        return x\n",
    "\n",
    "# Custom Dataset Class\n",
    "class VibrationDataset(Dataset):\n",
    "    def __init__(self, data_tensors, labels):\n",
    "        self.data_tensors = data_tensors\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data_tensors[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Load and Split Dataset\n",
    "def prepare_dataloaders(data, labels, batch_size=16):\n",
    "    dataset = VibrationDataset(data, labels)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_count = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            if early_stop_count >= 5:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(data_loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = prepare_dataloaders(x_data, y_labels, batch_size=16)\n",
    "        \n",
    "model = HybridResNetEfficientNet(num_classes=4)\n",
    "train_model(model, train_loader, val_loader, num_epochs=20, lr=0.001)\n",
    "\n",
    "print(\"Training complete! Evaluating on test set...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
