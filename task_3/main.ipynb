{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset for CASIA v2 with preprocessing\n",
    "class CASIADataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, apply_fft=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.apply_fft = apply_fft\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label, category in enumerate(['authentic', 'tampered']):\n",
    "            category_path = os.path.join(root_dir, category)\n",
    "            for img_name in os.listdir(category_path):\n",
    "                img_path = os.path.join(category_path, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(label)\n",
    "    \n",
    "    def preprocess_fft(self, image):\n",
    "        gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "        f = np.fft.fft2(gray)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)\n",
    "        \n",
    "        # Convert grayscale FFT output to 3-channel\n",
    "        magnitude_spectrum = np.stack([magnitude_spectrum] * 3, axis=-1)  \n",
    "\n",
    "        return Image.fromarray(magnitude_spectrum.astype(np.uint8))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.apply_fft:\n",
    "            image = self.preprocess_fft(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_dataset = CASIADataset(root_dir=\"dataset/train\", transform=transform, apply_fft=True)\n",
    "val_dataset = CASIADataset(root_dir=\"dataset/val\", transform=transform, apply_fft=True)\n",
    "test_dataset = CASIADataset(root_dir=\"dataset/test\", transform=transform, apply_fft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class ForgeryCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ForgeryCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ForgeryCNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += ((outputs > 0.5).float() == labels).sum().item()\n",
    "        \n",
    "        val_loss, val_correct = 0, 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += ((outputs > 0.5).float() == labels).sum().item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}, Accuracy: {correct/len(train_loader.dataset):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_correct/len(val_loader.dataset):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.6150, Accuracy: 0.7069, Val Loss: 0.6006, Val Acc: 0.7086\n",
      "Epoch 2/10 - Loss: 0.5963, Accuracy: 0.7079, Val Loss: 0.5851, Val Acc: 0.7076\n",
      "Epoch 3/10 - Loss: 0.5833, Accuracy: 0.7087, Val Loss: 0.5743, Val Acc: 0.7105\n",
      "Epoch 4/10 - Loss: 0.5780, Accuracy: 0.7100, Val Loss: 0.5720, Val Acc: 0.7171\n",
      "Epoch 5/10 - Loss: 0.5733, Accuracy: 0.7075, Val Loss: 0.5548, Val Acc: 0.7267\n",
      "Epoch 6/10 - Loss: 0.5711, Accuracy: 0.7113, Val Loss: 0.5554, Val Acc: 0.7248\n",
      "Epoch 7/10 - Loss: 0.5734, Accuracy: 0.7073, Val Loss: 0.5673, Val Acc: 0.7181\n",
      "Epoch 8/10 - Loss: 0.5673, Accuracy: 0.7134, Val Loss: 0.5588, Val Acc: 0.7210\n",
      "Epoch 9/10 - Loss: 0.5583, Accuracy: 0.7197, Val Loss: 0.5686, Val Acc: 0.7324\n",
      "Epoch 10/10 - Loss: 0.5385, Accuracy: 0.7253, Val Loss: 0.5599, Val Acc: 0.7219\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(images).squeeze()\n",
    "            test_correct += ((outputs > 0.5).float() == labels).sum().item()\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_correct / len(test_loader.dataset):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7157\n"
     ]
    }
   ],
   "source": [
    "# Run model on test data\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
